/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import dotenv from "dotenv";
dotenv.config();
/**
 * Example usage of the open-router SDK
 *
 * To run this example from the examples directory:
 * npm run build && npx tsx chatCreateChatCompletion.example.ts
 */

import { OpenRouter } from "open-router";

const openRouter = new OpenRouter({
  bearerAuth: process.env["OPENROUTER_BEARER_AUTH"] ?? "",
});

async function main() {
  const isStreaming = true; // Set to false for non-streaming response
  
  const result = await openRouter.chat.complete({
    model: "openai/gpt-3.5-turbo",
    stream: isStreaming,
    messages: [
      {
        role: "user",
        content: "Hello, how are you?",
      },
    ],
  });

  // Logical evaluator to handle response based on stream setting
  if (isStreaming) {
    console.log("Streaming response:");
    for await (const chunk of result) {
      if (chunk.data?.choices?.[0]?.delta?.content) {
        process.stdout.write(chunk.data.choices[0].delta.content);
      }
    }
    console.log("\n\nStreaming completed");
  } else {
    console.log("Non-streaming response:");
    console.log(JSON.stringify(result, null, 2));
  }
}

main()
