/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import { chatSend, SendAcceptEnum } from "../funcs/chatSend.js";
import { EventStream } from "../lib/event-streams.js";
import { ClientSDK, RequestOptions } from "../lib/sdks.js";
import * as models from "../models/index.js";
import * as operations from "../models/operations/index.js";
import { unwrapAsync } from "../types/fp.js";

export { SendAcceptEnum } from "../funcs/chatSend.js";

export class Chat extends ClientSDK {
  /**
   * Create a chat completion
   *
   * @remarks
   * Sends a request for a model response for the given chat conversation. Supports both streaming and non-streaming modes.
   */
  async send(
    request: models.ChatGenerationParams & { stream?: false | undefined },
    options?: RequestOptions & { acceptHeaderOverride?: SendAcceptEnum },
  ): Promise<models.ChatResponse>;
  async send(
    request: models.ChatGenerationParams & { stream: true },
    options?: RequestOptions & { acceptHeaderOverride?: SendAcceptEnum },
  ): Promise<EventStream<models.ChatStreamingResponseChunk>>;
  async send(
    request: models.ChatGenerationParams,
    options?: RequestOptions & { acceptHeaderOverride?: SendAcceptEnum },
  ): Promise<operations.SendChatCompletionRequestResponse>;
  async send(
    request: models.ChatGenerationParams,
    options?: RequestOptions & { acceptHeaderOverride?: SendAcceptEnum },
  ): Promise<operations.SendChatCompletionRequestResponse> {
    return unwrapAsync(chatSend(
      this,
      request,
      options,
    ));
  }
}
